name: Deploy IQGeo to EKS

on:
  push:
    branches: [main]
    paths:
      - 'k8s/**'
      - '.github/workflows/deploy.yaml'
  workflow_dispatch:
    inputs:
      action:
        description: 'Deployment action'
        required: true
        default: 'deploy'
        type: choice
        options:
          - deploy
          - upgrade
          - rollback
          - status

env:
  AWS_REGION: us-east-1
  CLUSTER_NAME: IQGEO-POC-Cluster-tf
  NAMESPACE: iqgeo

jobs:
  deploy:
    name: Deploy to EKS
    runs-on: self-hosted

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        run: |
          aws configure set region ${{ env.AWS_REGION }}
          aws sts get-caller-identity

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --name ${{ env.CLUSTER_NAME }} --region ${{ env.AWS_REGION }}
          kubectl cluster-info

      - name: Create namespace
        run: |
          kubectl apply -f k8s/namespace.yaml

      - name: Apply storage configuration
        run: |
          kubectl apply -f k8s/storage.yaml

      - name: Check secrets exist
        run: |
          echo "Checking if required secrets exist..."
          kubectl get secret harbor-registry-cred -n ${{ env.NAMESPACE }} || echo "WARNING: harbor-registry-cred not found"
          kubectl get secret iqgeo-db-secret -n ${{ env.NAMESPACE }} || echo "WARNING: iqgeo-db-secret not found"
          kubectl get secret iqgeo-license -n ${{ env.NAMESPACE }} || echo "WARNING: iqgeo-license not found"
      
      - name: Prepare resources for Helm
        if: github.event.inputs.action != 'status'
        run: |
          # Delete harbor-registry-cred if it exists without Helm ownership (Helm will recreate it)
          if kubectl get secret harbor-registry-cred -n ${{ env.NAMESPACE }} &>/dev/null; then
            if ! kubectl get secret harbor-registry-cred -n ${{ env.NAMESPACE }} -o jsonpath='{.metadata.labels.app\.kubernetes\.io/managed-by}' | grep -q Helm; then
              echo "Deleting existing harbor-registry-cred secret (Helm will recreate it)..."
              kubectl delete secret harbor-registry-cred -n ${{ env.NAMESPACE }}
            fi
          fi
          
          # Delete PVC if it exists (Helm will recreate it)
          # PVCs are immutable once bound, so we must always delete and recreate
          # This ensures Helm can create a fresh PVC with correct ownership
          if kubectl get pvc iqgeo-platform-shared-data -n ${{ env.NAMESPACE }} &>/dev/null; then
            echo "Deleting existing PVC (Helm will recreate it with correct ownership)..."
            # Delete pods using this PVC first
            kubectl get pods -n ${{ env.NAMESPACE }} -o json 2>/dev/null | jq -r '.items[] | select(.spec.volumes[]?.persistentVolumeClaim.claimName=="iqgeo-platform-shared-data") | .metadata.name' 2>/dev/null | while read pod; do
              if [ -n "$pod" ]; then
                echo "Deleting pod $pod that uses the PVC..."
                kubectl delete pod "$pod" -n ${{ env.NAMESPACE }} --grace-period=0 --force || true
              fi
            done
            sleep 3
            # Force delete the PVC
            kubectl delete pvc iqgeo-platform-shared-data -n ${{ env.NAMESPACE }} --wait=false || true
            # Wait for PVC to be fully deleted
            echo "Waiting for PVC to be deleted..."
            for i in {1..30}; do
              if ! kubectl get pvc iqgeo-platform-shared-data -n ${{ env.NAMESPACE }} &>/dev/null; then
                echo "PVC deleted successfully"
                break
              fi
              echo "Waiting for PVC deletion... ($i/30)"
              sleep 2
            done
            sleep 2
          fi
          
          # Delete Redis StatefulSet if it exists and is not managed by Helm (Helm will recreate it)
          if kubectl get statefulset iqgeo-redis-master -n ${{ env.NAMESPACE }} &>/dev/null; then
            if ! kubectl get statefulset iqgeo-redis-master -n ${{ env.NAMESPACE }} -o jsonpath='{.metadata.labels.app\.kubernetes\.io/managed-by}' | grep -q Helm; then
              echo "Deleting existing Redis StatefulSet (Helm will recreate it)..."
              kubectl delete statefulset iqgeo-redis-master -n ${{ env.NAMESPACE }} --cascade=orphan
            fi
          fi

      - name: Login to Harbor Registry
        if: github.event.inputs.action != 'status'
        env:
          HARBOR_USER: ${{ secrets.HARBOR_USERNAME }}
          HARBOR_PASS: ${{ secrets.HARBOR_PASSWORD }}
        run: |
          echo "Logging into Harbor registry..."
          if [ -z "$HARBOR_USER" ] || [ -z "$HARBOR_PASS" ]; then
            echo "ERROR: Harbor credentials not set in GitHub secrets"
            echo "Please add HARBOR_USERNAME and HARBOR_PASSWORD to repository secrets"
            exit 1
          fi
          echo "$HARBOR_PASS" | helm registry login harbor.delivery.iqgeo.cloud -u "$HARBOR_USER" --password-stdin

      - name: Deploy IQGeo Platform (Helm)
        if: github.event.inputs.action == 'deploy' || github.event.inputs.action == 'upgrade' || github.event_name == 'push'
        env:
          HARBOR_USER: ${{ secrets.HARBOR_USERNAME }}
          HARBOR_PASS: ${{ secrets.HARBOR_PASSWORD }}
        run: |
          echo "Deploying IQGeo Platform..."
          
          # Delete Redis StatefulSet if it exists (Helm will recreate it)
          # StatefulSets have restrictions on updates, so we need to delete and recreate
          if kubectl get statefulset iqgeo-redis-master -n ${{ env.NAMESPACE }} &>/dev/null; then
            echo "Deleting existing Redis StatefulSet (Helm will recreate it with correct config)..."
            kubectl delete statefulset iqgeo-redis-master -n ${{ env.NAMESPACE }} --cascade=orphan || true
            # Also delete the pods
            kubectl delete pods -l app.kubernetes.io/name=redis,app.kubernetes.io/instance=iqgeo -n ${{ env.NAMESPACE }} || true
            sleep 5
          fi
          
          # Delete deployments to fix pullSecrets format conflicts (Helm will recreate them)
          echo "Deleting existing deployments to fix pullSecrets format conflicts..."
          kubectl delete deployment iqgeo-platform -n ${{ env.NAMESPACE }} --cascade=orphan || true
          kubectl delete deployment iqgeo-iqgeo-memcached -n ${{ env.NAMESPACE }} --cascade=orphan || true
          
          # Delete cronjobs and jobs (they also have pullSecrets format issues)
          echo "Deleting existing cronjobs and jobs..."
          kubectl delete cronjob --all -n ${{ env.NAMESPACE }} || true
          kubectl delete job --all -n ${{ env.NAMESPACE }} || true
          sleep 3
          
          # Final check: Delete PVC if it still exists (must be done right before Helm upgrade)
          echo "Final check: Ensuring PVC is deleted before Helm upgrade..."
          if kubectl get pvc iqgeo-platform-shared-data -n ${{ env.NAMESPACE }} &>/dev/null; then
            echo "WARNING: PVC still exists, deleting it now..."
            # Delete any pods using the PVC
            kubectl get pods -n ${{ env.NAMESPACE }} -o json 2>/dev/null | jq -r '.items[] | select(.spec.volumes[]?.persistentVolumeClaim.claimName=="iqgeo-platform-shared-data") | .metadata.name' 2>/dev/null | while read pod; do
              if [ -n "$pod" ]; then
                echo "Force deleting pod $pod..."
                kubectl delete pod "$pod" -n ${{ env.NAMESPACE }} --grace-period=0 --force || true
              fi
            done
            sleep 2
            # Delete the PVC
            kubectl delete pvc iqgeo-platform-shared-data -n ${{ env.NAMESPACE }} --wait=false || true
            # Wait for deletion
            for i in {1..20}; do
              if ! kubectl get pvc iqgeo-platform-shared-data -n ${{ env.NAMESPACE }} &>/dev/null; then
                echo "PVC deleted successfully"
                break
              fi
              sleep 1
            done
            sleep 2
          else
            echo "PVC does not exist, proceeding with Helm upgrade"
          fi
          
          # Check if Helm chart exists locally or needs to be pulled
          if [ -f "charts/iqgeo-platform.tgz" ]; then
            CHART_PATH="charts/iqgeo-platform.tgz"
          else
            echo "Pulling IQGeo Helm chart from Harbor..."
            echo "$HARBOR_PASS" | helm registry login harbor.delivery.iqgeo.cloud -u "$HARBOR_USER" --password-stdin || true
            helm pull oci://harbor.delivery.iqgeo.cloud/helm/iqgeo-platform --destination charts/ || true
            CHART_PATH=$(ls charts/iqgeo-platform*.tgz 2>/dev/null | head -1)
          fi
          
          if [ -n "$CHART_PATH" ]; then
            helm upgrade --install iqgeo $CHART_PATH \
              -f k8s/values.yaml \
              --namespace ${{ env.NAMESPACE }} \
              --create-namespace \
              --force \
              --wait \
              --timeout 10m
          else
            echo "No Helm chart found. Skipping Helm deployment."
            echo "Please place the IQGeo Helm chart in charts/ directory"
          fi

      - name: Rollback deployment
        if: github.event.inputs.action == 'rollback'
        run: |
          echo "Rolling back IQGeo deployment..."
          helm rollback iqgeo -n ${{ env.NAMESPACE }}

      - name: Check deployment status
        run: |
          echo "=== Deployment Status ==="
          kubectl get pods -n ${{ env.NAMESPACE }}
          echo ""
          echo "=== Services ==="
          kubectl get svc -n ${{ env.NAMESPACE }}
          echo ""
          echo "=== Ingress ==="
          kubectl get ingress -n ${{ env.NAMESPACE }}
          echo ""
          echo "=== PVCs ==="
          kubectl get pvc -n ${{ env.NAMESPACE }}

      - name: Wait for pods to be ready
        if: github.event.inputs.action != 'status'
        run: |
          echo "Waiting for pods to be ready..."
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/instance=iqgeo -n ${{ env.NAMESPACE }} --timeout=300s || true

      - name: Show logs on failure
        if: failure()
        run: |
          echo "=== Pod Logs ==="
          for pod in $(kubectl get pods -n ${{ env.NAMESPACE }} -o jsonpath='{.items[*].metadata.name}'); do
            echo "--- Logs for $pod ---"
            kubectl logs $pod -n ${{ env.NAMESPACE }} --tail=50 || true
          done
          echo ""
          echo "=== Events ==="
          kubectl get events -n ${{ env.NAMESPACE }} --sort-by='.lastTimestamp' | tail -20

